The \appName\ system was designed with a specific target group in mind: Epigenitic researchers. This chapter will explain the needs of these users, the problems they faced before this system was provided and the requirements that were collected and taken into account during the project.
\nomenclature{Genomizer}{Collective name for the project.}
\section{Target group}

The target group for the \appName\ system is  \term{Epigenetic Cooperation Norrland (EpiCoN)}, a diverse group of researchers at \term{Ume√• University} made up of many different nationalities. Their main communication language is English.

\term{EpiCon} are involved in the research of how proteins bind to \term{DNA} strings and its effects. Experiments are carried out which yield large amounts of raw data. This information, combined with knowledge about the location of genes within a given genome, enable the researchers to gain valuable information about which proteins are active in enabling and disabling genes. These results are important in the study of how cells ''remember'' which genes should be enabled after cell division.

Previous to the \appName\ project the raw data files retrieved from experiments were manually processed by the researchers using inefficient \term{Perl} scripts. This process also involved using \term{Bowtie}\cite{BOWTIE}, a program used to unscramble the \term{DNA} data, and \term{LiftOver}\cite{LIFTOVER} which is used to adjust results to conform to different \term{genome releases}.

The researchers at \term{EpiCoN} have varying computer skills. While they all have basic computer knowledge, not all are familiar with more advanced computing tasks such as running scripts at command line level. As such, some researchers have become dependent on others to process the raw data. At \term{EpiCon} the researcher that has the knowledge to use all the scripts and software performs many of these time consuming tasks for other researchers.

From time to time students of molecular biology are interested in working with the data, however their access is limited to viewing and analysing the data. 

\nomenclature{Bowtie}{Program the preforms parsing of the raw data and counts base pairs}
\nomenclature{LiftOver}{Converts genome release versions.}
\nomenclature{Genome releases}{Constant research gives more understanding, new genome versions are often found.}

\section{Client needs}
The researchers at \term{EpiCoN} need a system to structure the large amount of genetic data they use daily. The requirements, as described below, were collected and handled as a number of \term{user stories}, each of which describe a desired function from the end users perspective. A complete list of the \term{user stories} are presented in \fullref{chap:userstories}. %When discussed below the title of the relevant \term{user story} will be used.
A overview of the requested system may be seen below in figure \ref{fig:requestOverview}. Where orange colored nodes are must have features while gray nodes are visions of the clients that may be implemented if time allows for it.

There are three main data types used in the research and that the system should handle: \term{raw}, \term{profile} and \term{region} data. \term{Raw} data is the raw output from an experiment and cannot be analysed directly. It is first processed to so called \term{profile} data. \term{Profile} data describes the amount of reads found for every base--pair in an organism's genome. \term{Region} data is further processed \term{profile} data consisting of the regions where every base--pair's read strength is above a given threshold and fault tolerance. The region gets a value based on the average of the base-pair reads for the given region.

\nomenclature{Region}{Region data is small parts of the profile data.}
\begin{figure}[h!]
\begin{tikzpicture}[ 
	font=\sffamily,
  every matrix/.style={ampersand replacement=\&,column sep=0.5cm,row sep=0.5cm},
  db/.style={cylinder, shape border rotate=90, draw, fill=orange!40, minimum height=2cm, minimum width=1.5cm},
  must/.style={rectangle, draw, fill=orange!40, minimum height=1cm, minimum width=2cm, font=\ttfamily\footnotesize},
  vision/.style={rectangle, draw, fill=gray!40, minimum height=1cm, minimum width=2cm, font=\ttfamily\footnotesize}, 
  both/.style={<->,>=stealth',shorten >=1pt,semithick,font=\sffamily\footnotesize},
  to/.style={->,>=stealth',shorten >=1pt,semithick,font=\sffamily\footnotesize},
  every node/.style={align=center}]
  
\matrix{
	\node[must] (proc) {Processing}; \&
	\node[must] (add) {Upload}; \&
	\node[vision] (visual) {Visualization}; \\
	\node[vision] (analys) {Analysis}; \& 
	\node[db] (B) {DB}; \& 
	\node[vision] (quality) {Quality\\ Control}; \\
 	\& 	\node[must] (extract) {Download}; \&
 	\node[must] (format) {Format Conversion}; \\
	};
	
	\draw[both] (proc) -- (B);
	\draw[to] (add) -- (B);
	\draw[both] (visual) -- (B);
	\draw[both] (analys) -- (B);
	\draw[both] (B) -- (quality);
	\draw[to] (B) -- (extract);	
	\draw[both] (format) -- (B);

\end{tikzpicture}
\caption{Overview of targeted system}
\label{fig:requestOverview}
\end{figure}

\subsection{Upload \& Download}

When conducting experiments the researchers generate \term{raw} data that generates what they call \term{Raw}-files. These files along with profile data, region data and genome release data may be added and related to an experiment. The requested functionality is to be able to upload these files to the database from multiple sources. The sources may be directly from an experiment conducted by the researchers or from official publications.

When results are published in scientific articles the \term{raw} data from the experiments are often also provided. One location where these \term{raw} data files can be published is the \term{GEO} (\term{Gene Expression Omnibus}) database. A desire to be able to initialize a upload to \appName with the source of the upload beeing  \term{GEO}.
\nomenclature{GEO}{Centralized database where article data can be found.}

\subsection{Database}
The \texttt{Database} module requested has the purpose to archive experiment data in a way of easy access. To allow for this the experiments and files associated with them needs to have information vital for good readability. This is solved with the help of annotations. The reaserchers must add annotations to files related to an experiment.
This data is the foundation for further research and so must be stored securely. To ensure security the client requested a system for authorization that protects the data from outside tampering. To protect against hardware failure there exists a request for a backup system.

\subsection{Processing}
The unordered \term{raw} data gained from an experiment requires processing in order to be analysed. The researchers have written a number of scripts and, when combined with the \term{BowTie} algorithm, generate \term{profile} data. In this format the \term{DNA} pieces are ordered and mapped to the \term{DNA} string. It is important that the system automates this process so that all researchers can easily process the large \term{raw} files.

As new discoveries are made in the area, new standards for the order of the base pairs in a \term{DNA} string are set. This results in a new \term{Genome Release} for a specific species. These are obtained as a set of files specifying this order and are used in the processing of \term{raw} data. \appName\ must support the uploading of new sets of \term{genome release} files to be used in processing otherwise the system will very quickly become outdated. 

It would also be an advantage if the system could carry out further processing from \term{profile} to \term{region} files.

After processing, the resulting data files should be annotated and saved in the database alongside their parent files. It is important that the parent files remain traceable and that the parameters used in processing are saved so that the process can be repeated and confirmed.

\subsection{Format Conversion}
\appName\ should also provide a way to convert \term{profile} data files between different genome releases. This involves the ability to upload new \term{Chain Files} which enable conversion using \term{LiftOver} and the embedding of this program.

It is not uncommon for errors in a new release to be discovered after publication. It is therefore also important to store files generated using older genome releases for some time after a new release is published.

\nomenclature{Chain files}{Genome release files with small alterations to previous genome releases.}
